{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to bteyu","text":""},{"location":"Intro-Machine-Learning/01.%20Introduction/","title":"01. Introduction","text":"","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#daily-quote","title":"Daily Quote","text":"<p>[!quote] When you are offended at any man's fault, turn to yourself and study your own failings. Then you will forget your anger. \u2014 Epictetus</p>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#tag","title":"Tag","text":"<p>Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.</p> <p>The technique of using linear interpolation for tabulation was believed to be used by Babylonian astronomers and mathematicians in Seleucid Mesopotamia (last three centuries BC), and by the Greek astronomer and mathematician, Hipparchus (2nd century BC). A description of linear interpolation can be found in the Almagest (2nd century AD) by Ptolemy. </p>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#regression","title":"Regression","text":"Python<pre><code>import numpy.random as npr\nimport jax.numpy as np\nfrom jax import grad\nimport matplotlib.pyplot as plt\n\n# first generate some random data\nX = npr.uniform(0, 1, 300)\ntrue_w, true_b = 2, 1\n# add some noise to the labels\nY = X*true_w + true_b + 0.2*npr.randn(300) + p.sin(2*np.pi*X)\n\nplt.scatter(X, Y, marker='.', color='blue')\nplt.plot(np.sort(X),  np.sort(X)*true_w + true_b + np.sin(2*np.pi*np.sort(X)), color='black')\nplt.show()\n</code></pre> <p>Regression is a fundamental concept in statistics and machine learning that models the relationship between a dependent variable (target) and one or more independent variables (features). It is widely used for prediction, inference, and understanding data trends.</p>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#1-linear-regression","title":"1. Linear Regression","text":"<p>Linear regression assumes a linear relationship between the input X and output Y. The model is expressed as:</p>  Y = \\beta_0 + \\beta_1 X + \\epsilon  <p>where:</p> <ul> <li> <p>\\beta_0 is the intercept (constant term).</p> </li> <li> <p>\\beta_1 is the coefficient (slope).</p> </li> <li> <p>\\epsilon is the error term (captures noise or randomness in data).</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#key-assumptions","title":"Key Assumptions:","text":"<ol> <li> <p>Linearity: The relationship between X and Y is linear.</p> </li> <li> <p>Independence: Observations are independent.</p> </li> <li> <p>Homoscedasticity: The variance of errors remains constant across values of X.</p> </li> <li> <p>Normality of Errors: The residuals (errors) follow a normal distribution.</p> </li> </ol>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#how-it-works","title":"How It Works:","text":"<p>Linear regression finds the best-fit line by minimizing the sum of squared errors, using Ordinary Least Squares (OLS):</p>  \\min_{\\beta} \\sum (Y_i - \\hat{Y}_i)^2  <p>where \\hat{Y}_i is the predicted value.</p>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#2-multiple-linear-regression","title":"2. Multiple Linear Regression","text":"<p>Extends linear regression to multiple features:</p>  Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_n X_n + \\epsilon  <p>It captures the influence of multiple factors on the target variable.</p>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#3-logistic-regression-for-classification","title":"3. Logistic Regression (For Classification)","text":"<p>Despite the name, logistic regression is used for classification, not regression. It models the probability of a binary outcome:</p>  P(Y=1 | X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X)}}  <ul> <li> <p>It uses the logit (sigmoid) function to map predictions between 0 and 1.</p> </li> <li> <p>Generalized linear model (GLM): It assumes a Bernoulli distribution for Y.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#4-polynomial-regression","title":"4. Polynomial Regression","text":"<p>If a relationship is non-linear, we extend linear regression to include polynomial terms:</p>  Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\dots + \\beta_n X^n + \\epsilon  <ul> <li> <p>It models curves instead of straight lines.</p> </li> <li> <p>The higher the polynomial degree, the better it fits, but risk of overfitting increases.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#5-generalized-linear-model-glm","title":"5. Generalized Linear Model (GLM)","text":"<p>A Generalized Linear Model (GLM) extends ordinary linear regression by allowing for:</p> <ol> <li> <p>Different Distributions: The response variable Y can follow different distributions (not just normal).</p> </li> <li> <p>Link Function: Instead of modeling Y directly, GLMs use a function to relate the mean E[Y] to the linear predictor.</p> </li> </ol>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#general-form-of-glm","title":"General Form of GLM","text":"<p>For a response variable Y, GLMs assume:</p>  g(E[Y]) = X\\beta  <p>Where:</p> <ul> <li> <p>X is the matrix of input features.</p> </li> <li> <p>\\beta are the coefficients to learn.</p> </li> <li> <p>g(\\cdot) is the link function, which connects the expected value of Y to a linear combination of inputs.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#key-components-of-glm","title":"Key Components of GLM","text":"<ol> <li> <p>Exponential Family of Distributions: Y comes from a family of distributions (Normal, Poisson, Binomial, etc.).</p> </li> <li> <p>Link Function g(\\cdot): Transforms E[Y] into a linear model.</p> </li> <li> <p>Linear Predictor: X\\beta remains a linear combination of inputs.</p> </li> </ol>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#why-glms","title":"Why GLMs?","text":"<ul> <li> <p>Generalizes linear regression to different distributions.</p> </li> <li> <p>Uses Maximum Likelihood Estimation (MLE) instead of least squares.</p> </li> <li> <p>More flexible than simple linear regression.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#key-metrics-for-evaluating-regression-models","title":"Key Metrics for Evaluating Regression Models","text":"<p>To measure the performance of a regression model, we use:</p> <ol> <li> <p>Mean Squared Error (MSE): Measures average squared differences between actual and predicted values.</p>    MSE = \\frac{1}{n} \\sum (Y_i - \\hat{Y}_i)^2    </li> <li> <p>Root Mean Squared Error (RMSE): Square root of MSE, which brings errors to the same unit as the data.</p>  RMSE = \\sqrt{MSE}  </li> <li> <p>Mean Absolute Error (MAE): Measures the average absolute differences.</p>  MAE = \\frac{1}{n} \\sum |Y_i - \\hat{Y}_i|  </li> <li> <p>R^2 (Coefficient of Determination): Explains the proportion of variance explained by the model.</p>  R^2 = 1 - \\frac{\\sum (Y_i - \\hat{Y}_i)^2}{\\sum (Y_i - \\bar{Y})^2}  </li> </ol> Python<pre><code># the linear model\ndef linear(params, x):\n    w,b = params\n    return w*x + b\n\ndef loss(params, dataset):\n    x, y = dataset\n    pred = linear(params, x)\n    return np.square(pred - y).mean()\n\n# gradient function\nloss_grad = grad(loss)\n\niterations = 500\nstep_size = 0.1\ndataset = (X, Y)\nw, b = 1.5, 2. # initial values for the parameters\nfor i in range(iterations):\n    params = (w, b)\n    loss_ = loss(params, dataset)\n    # compute gradient w.r.t model parameters\n    params_grad = loss_grad(params, dataset)\n    # update parameters\n    w -= step_size * params_grad[0]\n    b -= step_size * params_grad[1]\n    #print(loss_)\n\nprint(\"loss: {}, params {}\".format(loss_, params))\n\nplt.scatter(X, Y, marker='.', color='blue')\nplt.plot(np.sort(X),  np.sort(X)*true_w + true_b + np.sin(2*np.pi*np.sort(X)), color='black')\nplt.plot(np.sort(X), linear(params, np.sort(X)), color='red')\nplt.show()\n</code></pre> <p>loss: 0.25392094254493713, params (Array(0.26151434, dtype=float32, weak_type=True), Array(1.8786527, dtype=float32, weak_type=True))</p> <p></p>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#optimization","title":"Optimization","text":"<p>To reduce RMSE, we can use different strategies:</p>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#a-dataset-improvements","title":"A. Dataset Improvements","text":"<ul> <li> <p>More Data: Collect additional samples to improve generalization.</p> </li> <li> <p>Data Augmentation: Create synthetic data using transformations (e.g., image rotations, SMOTE for imbalanced data).</p> </li> <li> <p>Synthetic Data Generation: GANs, Variational Autoencoders, or bootstrapping.</p> </li> <li> <p>Handling Missing Data: Imputation methods (mean, median, KNN imputation).</p> </li> <li> <p>Class Balancing: Oversampling, undersampling, or synthetic data generation (e.g., SMOTE for imbalanced datasets).</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#b-improve-model-complexity-vc-dimension-bias-variance-tradeoff","title":"B. Improve Model Complexity (VC Dimension, Bias-Variance Tradeoff)","text":"<ul> <li> <p>Choose the Right Model: Simple models reduce overfitting; complex models improve accuracy but need regularization.</p> </li> <li> <p>Polynomial Features: Increase model complexity for non-linearity.</p> </li> <li> <p>Early Stopping: Stop training when validation loss starts increasing.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#vc-dimension-vapnik-chervonenkis-dimension","title":"VC Dimension (Vapnik-Chervonenkis Dimension)","text":"<p>VC dimension is a fundamental concept in statistical learning theory that measures the capacity or complexity of a model class. It quantifies how well a model can shatter (perfectly classify) different sets of data points.</p> <p>[!Definition] The VC dimension of a hypothesis class \\mathcal{H} is the largest number of points that can be shattered by some hypothesis in \\mathcal{H}.</p> <ul> <li> <p>A model shatters a dataset if it can classify all possible labelings (all 2^n assignments of class labels for n points).</p> </li> <li> <p>Higher VC dimension \u2192 More complex model \u2192 Higher capacity to fit data (risk of overfitting).</p> </li> <li> <p>Example:</p> <ul> <li> <p>A linear classifier in 2D can shatter at most 3 points, so its VC dimension is 3.</p> </li> <li> <p>A linear classifier in d-dimensions has VC dimension d+1.</p> </li> </ul> </li> </ul> <p>Implications:</p> <ul> <li> <p>Lower VC dimension \u2192 Model is simple (underfitting risk).</p> </li> <li> <p>Higher VC dimension \u2192 Model is complex (overfitting risk).</p> </li> <li> <p>VC Theorem: If a model has a finite VC dimension d, it generalizes well if the number of training examples n is sufficiently larger than d.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#other-ways-to-measure-model-complexity","title":"Other Ways to Measure Model Complexity","text":"<ol> <li> <p>Rademacher Complexity</p> <ul> <li> <p>Measures how well a hypothesis class can fit random noise.</p> </li> <li> <p>If a model class has high Rademacher complexity, it can overfit random labels.</p> </li> </ul> </li> <li> <p>PAC-Bayes, </p> </li> <li> <p>margin-based bounds </p> </li> <li> <p>Geometric way</p> </li> </ol> <ul> <li> <p>If the model is too simple, it underfits. We can:</p> </li> <li> <p>Use polynomial regression instead of linear.</p> </li> <li> <p>Add interaction terms.</p> </li> <li> <p>Use nonlinear models (e.g., random forests, neural networks). Python<pre><code># the nonlinear model\ndef nonlinear(params, x):\n    res = 0.0\n    for idx, weight in enumerate(params):\n        res += weight * x ** idx\n    return res\n\ndef loss(params, dataset):\n    x, y = dataset\n    pred = nonlinear(params, x)\n    return np.square(pred - y).mean()\n\n# gradient function\nloss_grad = grad(loss)\n\ndataset = (X, Y)\nfor order in range(2, 15, 2):\n    weights = np.ones(order) * 1.5 \n\n    for i in range(iterations):\n        params = weights\n        loss_ = loss(params, dataset)\n        params_grad = loss_grad(params, dataset)\n        # update parameters\n        for j in range(order):\n            weights = weights.at[j].set(weights[j] - step_size * params_grad[j])\n\n    print(\"Order: {}, loss: {}\".format(order, loss_))\n</code></pre></p> </li> </ul> <p>Order: 2, loss: 0.25392 Order: 4, loss: 0.24112 Order: 6, loss: 0.19777 Order: 8, loss: 0.16633 Order: 10, loss: 0.15277 Order: 12, loss: 0.15003 Order: 14, loss: 0.15189</p> <p></p>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#c-regularization-avoid-overfitting","title":"C. Regularization (Avoid Overfitting)","text":"<ul> <li> <p>L1 Regularization (Lasso \\ell_1): Encourages sparsity (feature selection).</p> </li> <li> <p>L2 Regularization (\\ell_2 Ridge): Reduces large weights, preventing overfitting.</p> </li> <li> <p>Elastic Net: Combination of L1 and L2.</p> </li> <li> <p>Dropout (Neural Networks): Randomly removes neurons during training.</p> </li> <li> <p>Batch Normalization: Normalizes activations in deep networks.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#ridge-regressionl2-regulation","title":"Ridge regression(L2 regulation)","text":"Python<pre><code>from sklearn import linear_model\n\nidx = np.argsort(X)\n\n# encoder\nZ = np.concatenate([X[idx].reshape(-1, 1)**n for n in range(1, 10)], axis=1)\n\n# ridge regression\nreg = linear_model.Ridge(alpha=1e-8)\nreg.fit(Z, Y[idx])\n</code></pre> <p>Mean Squared Error (Loss): 0.04097932204604149</p> <p></p> <p>Ridge regression is a type of linear regression that includes an L_2-norm penalty to prevent overfitting. The objective function is:</p>  \\min_{\\beta} \\sum_{i=1}^{n} (y_i - X_i \\beta)^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2  <p>where:</p> <ul> <li> <p>y_i are the observed values,</p> </li> <li> <p>X_i are the input features,</p> </li> <li> <p>\\beta are the regression coefficients,</p> </li> <li> <p>\\lambda is the regularization parameter, which controls the trade-off between fitting the data and keeping coefficients small.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#intuition","title":"Intuition:","text":"<ul> <li> <p>Adding \\lambda \\sum \\beta_j^2 shrinks the coefficients \\beta_j towards zero but never exactly zero.</p> </li> <li> <p>Ridge regression helps when features are highly correlated, reducing variance and preventing overfitting.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#relation-to-prior-distribution-bayesian-interpretation","title":"Relation to Prior Distribution (Bayesian Interpretation)","text":"<p>Ridge regression can be seen as Bayesian linear regression with a Gaussian prior on the coefficients:</p> <p>$$</p> <p>\\beta_j \\sim \\mathcal{N}(0, \\tau^2)</p> <p>$$</p> <p>where \\tau^2 = \\frac{1}{\\lambda}. This means:</p> <ul> <li> <p>The model assumes that larger coefficients are less likely, which enforces shrinkage.</p> </li> <li> <p>A stronger prior (larger \\lambda) shrinks the coefficients more.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#lasso-regressionl1-regulation","title":"Lasso Regression(L1 Regulation)","text":"Python<pre><code>reg = linear_model.Lasso(alpha=1e-8)\nreg.fit(Z, Y[idx])\n\npredictions = reg.predict(Z)\nmse = np.mean((predictions - Y[idx]) ** 2)\nprint(f\"Mean Squared Error (Loss): {mse}\")\n</code></pre> <p>Mean Squared Error (Loss): 0.043433766812086105</p> <p>Lasso (Least Absolute Shrinkage and Selection Operator) is another regularized regression method, but it uses an L_1-norm penalty instead of L_2:</p>  \\min_{\\beta} \\sum_{i=1}^{n} (y_i - X_i \\beta)^2 + \\lambda \\sum_{j=1}^{p} |\\beta_j|","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#intuition_1","title":"Intuition:","text":"<ul> <li> <p>The absolute value penalty forces some coefficients to be exactly zero, effectively performing feature selection.</p> </li> <li> <p>Unlike Ridge regression, Lasso can create sparse models, making it useful when there are many irrelevant features.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#relation-to-prior-distribution","title":"Relation to Prior Distribution","text":"<p>Lasso regression corresponds to Bayesian regression with a Laplace prior:</p>  \\beta_j \\sim \\text{Laplace}(0, b)  <p>where b = \\frac{1}{\\lambda}. The Laplace distribution is sharply peaked at zero, which encourages sparsity. This is why Lasso forces some coefficients to be exactly zero.</p>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#why-does-l1-regularization-perform-feature-selection","title":"Why Does L1 Regularization Perform Feature Selection?","text":"<ol> <li> <p>Sparsity Effect:</p> <ul> <li> <p>The L1 penalty encourages some coefficients \\beta_j to be exactly zero.</p> </li> <li> <p>This leads to a sparse model, where only a subset of the features are retained.</p> </li> <li> <p>Features with zero coefficients are effectively removed from the model.</p> </li> </ul> </li> <li> <p>Optimization Property:</p> <ul> <li> <p>The L1 norm creates a non-differentiable point at \\beta_j = 0, which forces some coefficients to shrink to zero.</p> </li> <li> <p>Geometrically, the constraint region forms a diamond shape, which makes it more likely for the optimal solution to lie on the axes (i.e., some coefficients are zero).</p> </li> </ul> </li> <li> <p>Automatic Feature Selection:</p> <ul> <li> <p>Unlike L2 regularization (Ridge regression), which only shrinks coefficients towards zero, L1 eliminates irrelevant features entirely.</p> </li> <li> <p>This is useful when you have high-dimensional data with many irrelevant or redundant features.</p> </li> </ul> </li> </ol>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#elastic-net-regression","title":"Elastic Net Regression","text":"<p>Elastic Net combines both Ridge (L_2) and Lasso (L_1) penalties:</p>  \\min_{\\beta} \\sum_{i=1}^{n} (y_i - X_i \\beta)^2 + \\lambda_1 \\sum_{j=1}^{p} |\\beta_j| + \\lambda_2 \\sum_{j=1}^{p} \\beta_j^2  <p>where:</p> <ul> <li> <p>\\lambda_1 controls the Lasso part (feature selection).</p> </li> <li> <p>\\lambda_2 controls the Ridge part (shrinkage and handling collinearity).</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#intuition_2","title":"Intuition:","text":"<ul> <li> <p>If features are highly correlated, Lasso can randomly pick one and discard the others. Elastic Net avoids this issue by keeping a mix of features.</p> </li> <li> <p>It selects features like Lasso while shrinking coefficients like Ridge.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#relation-to-prior-distribution_1","title":"Relation to Prior Distribution","text":"<p>Elastic Net corresponds to a Mixture Prior:</p> <ul> <li> <p>It assumes a combination of Gaussian (Ridge) and Laplace (Lasso) priors on the coefficients.</p> </li> <li> <p>This means that some coefficients get shrunk (like Ridge), while others get sparsified (like Lasso).</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#d-feature-engineering-selection","title":"D. Feature Engineering &amp; Selection","text":"<ul> <li> <p>One-hot Encoding: Convert categorical variables into numerical.</p> </li> <li> <p>Standardization (Z-score, Min-Max Scaling): Normalize feature values.</p> </li> <li> <p>Other feature transformations (log, power, etc.).</p> </li> <li> <p>Feature Selection Methods:</p> <ul> <li> <p>Univariate Tests: Select top-ranked features based on correlation.</p> </li> <li> <p>Recursive Feature Elimination (RFE): Iteratively remove less important features.</p> </li> <li>Lasso (L1 Regularization): Selects only important features.</li> <li>Remove irrelevant or redundant features to reduce noise.</li> </ul> </li> </ul> Python<pre><code>dataset = (X, np.log(Y))\n\n# omit repeated code\nplt.plot(np.sort(X), np.exp(linear(params, np.sort(X))), color='red')\n</code></pre> <p>loss: 0.07207518070936203</p> <p></p> <ul> <li>Perform dimensionality reduction (PCA, autoencoders).</li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#e-dimensionality-reduction","title":"E. Dimensionality Reduction","text":"<ul> <li> <p>PCA (Principal Component Analysis): Reduces correlated features.</p> </li> <li> <p>LDA (Linear Discriminant Analysis): Used in classification tasks.</p> </li> <li> <p>t-SNE &amp; UMAP: Nonlinear dimensionality reduction for visualization.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#f-reduce-outliers-noise","title":"F. Reduce Outliers &amp; Noise","text":"<ul> <li> <p>Z-score, IQR Method: Remove extreme outliers.</p> </li> <li> <p>Robust Loss Functions: Huber loss, quantile loss.</p> </li> <li> <p>Denoising Methods: Gaussian smoothing, moving average.</p> <ul> <li>RMSE is sensitive to outliers. </li> </ul> </li> </ul> Python<pre><code>from sklearn.ensemble import IsolationForest\n\niso_forest = IsolationForest(contamination=0.05)  \noutliers = iso_forest.fit_predict(X.reshape(-1, 1))\n\ninliers = outliers == 1\n\nX_filtered = X[inliers]\nY_filtered = Y[inliers]\n</code></pre> <p>Mean Squared Error (Loss): 0.11134050786495209</p> <ul> <li>Robust regression (Huber loss). Python<pre><code>reg = linear_model.HuberRegressor(alpha=0.0, epsilon=1.5)\n</code></pre> <p>Mean Squared Error (Loss): 0.03720296174287796</p> </li> </ul> <p>The Huber loss is a combination of squared loss (used in ordinary least squares) and absolute loss (used in robust regression), designed to handle outliers more gracefully. It is particularly useful when you want a model that is robust to outliers but still penalizes small errors quadratically, like the regular least squares.</p> <p>[!Definition] Definition The Huber loss function L_\\delta(y, \\hat{y}) is defined as: $$ L_\\delta(y, \\hat{y}) = \\begin{cases} \\frac{1}{2}(y - \\hat{y})^2, &amp; \\text{for} \\ |y - \\hat{y}| \\leq \\delta \\ \\delta |y - \\hat{y}| - \\frac{1}{2} \\delta^2, &amp; \\text{for} \\ |y - \\hat{y}| &gt; \\delta \\end{cases} $$ where: - y is the true value, - \\hat{y} is the predicted value, - \\delta is a threshold that controls the transition between quadratic and linear loss.</p>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#intuition_3","title":"Intuition:","text":"<ul> <li> <p>For errors less than or equal to \\delta, the loss behaves like a squared error (quadratic), which heavily penalizes small deviations.</p> </li> <li> <p>For large errors (i.e., when the error is greater than \\delta), the loss behaves like absolute error, which grows linearly, avoiding excessive penalties for large deviations or outliers.</p> </li> </ul> <p>This makes the Huber loss more robust to outliers compared to squared error (which can be highly influenced by large deviations).</p>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#g-optimize-hyperparameters","title":"G. Optimize Hyperparameters","text":"<ul> <li> <p>Grid Search: Exhaustively tries all combinations.</p> </li> <li> <p>Random Search: Randomly samples hyperparameters.</p> </li> <li> <p>Bayesian Optimization: Uses probability to find optimal hyperparameters.</p> </li> <li> <p>Evolutionary Algorithms: Genetic algorithms to find the best configuration.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#grid-search","title":"Grid Search","text":"<ul> <li> <p>Exhaustively searches over a predefined set of hyperparameters.</p> </li> <li> <p>Creates a grid of possible values and evaluates each combination.</p> </li> </ul> <p>Example:</p> <p>If we have:</p> <ul> <li> <p>Learning rate \\eta in {0.001, 0.01, 0.1}</p> </li> <li> <p>Regularization \\lambda in {0.001, 0.01, 0.1}</p> </li> </ul> <p>Grid search tests all 3 \\times 3 = 9 combinations.</p> <p>\u2705 Pros:</p> <ul> <li> <p>Guarantees best result within search space.</p> </li> <li> <p>Simple and systematic.</p> </li> </ul> <p>\u274c Cons:</p> <ul> <li> <p>Computationally expensive.</p> </li> <li> <p>Wasteful if only a few hyperparameters matter.</p> </li> </ul> Python<pre><code>from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\n\nparam_grid = {\n    'n_estimators': [10, 50, 100],\n    'max_depth': [3, 5, 10],\n    'min_samples_split': [2, 5, 10]\n}\n\nclf = RandomForestClassifier()\ngrid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best parameters:\", grid_search.best_params_)\nprint(\"Best score:\", grid_search.best_score_)\n</code></pre>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#random-search","title":"Random Search","text":"<ul> <li> <p>Randomly samples hyperparameter values from a distribution.</p> </li> <li> <p>Does not evaluate all combinations but instead explores the space stochastically.</p> </li> </ul> <p>Example:</p> <ul> <li>Instead of testing all 9 combinations, randomly select 5 combinations.</li> </ul> <p>\u2705 Pros:</p> <ul> <li> <p>Often more efficient than grid search.</p> </li> <li> <p>Works well when only a few hyperparameters significantly affect performance.</p> </li> <li> <p>More effective in high-dimensional spaces.</p> </li> </ul> <p>\u274c Cons: - No guarantee of finding the absolute best hyperparameters.</p> Python<pre><code>from sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\n\nparam_dist = {\n    'n_estimators': randint(10, 200),\n    'max_depth': randint(3, 20),\n    'min_samples_split': randint(2, 20)\n}\n\nclf = RandomForestClassifier()\nrandom_search = RandomizedSearchCV(clf, param_dist, n_iter=20, cv=5, scoring='accuracy', random_state=42)\nrandom_search.fit(X_train, y_train)\n\nprint(\"Best parameters:\", random_search.best_params_)\nprint(\"Best score:\", random_search.best_score_)\n</code></pre>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#bayesian-optimization-bo","title":"Bayesian Optimization (BO)","text":"<p>Grid and random search do not use past evaluations to guide future searches. Bayesian Optimization (BO) does.</p>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#how-it-works_1","title":"How It Works","text":"<ol> <li> <p>Define a prior belief about the function mapping hyperparameters to performance.</p> </li> <li> <p>Use a surrogate model (usually a Gaussian Process) to estimate the objective function.</p> </li> <li> <p>Select the next hyperparameter set based on an acquisition function (e.g., Expected Improvement, Upper Confidence Bound).</p> </li> <li> <p>Evaluate the model with these hyperparameters.</p> </li> <li> <p>Update the belief and repeat.</p> </li> </ol>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#key-components-of-bo","title":"Key Components of BO:","text":"<ul> <li> <p>Surrogate Model: </p> <ul> <li> <p>Typically a Gaussian Process (GP) that models the unknown function.</p> </li> <li> <p>Uses previous evaluations to estimate performance at new points.</p> </li> </ul> </li> <li> <p>Acquisition Function: </p> <ul> <li>Guides the search by balancing exploration (trying new areas) and exploitation (focusing on promising regions).</li> </ul> </li> <li> <p>Common choices:   </p> <ul> <li> <p>Expected Improvement (EI): Pick points expected to improve the best result.</p> </li> <li> <p>Upper Confidence Bound (UCB): Pick points with high uncertainty.</p> </li> </ul> </li> </ul> Python<pre><code>from bayes_opt import BayesianOptimization\n\ndef rf_cv(n_estimators, max_depth, min_samples_split):\n    model = RandomForestClassifier(\n        n_estimators=int(n_estimators),\n        max_depth=int(max_depth),\n        min_samples_split=int(min_samples_split),\n        random_state=42\n    )\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)  # Optimization objective\n\n# Define hyperparameter space\npbounds = {\n    'n_estimators': (10, 200),\n    'max_depth': (3, 20),\n    'min_samples_split': (2, 20)\n}\n\noptimizer = BayesianOptimization(\n    f=rf_cv,\n    pbounds=pbounds,\n    random_state=42\n)\n\noptimizer.maximize(init_points=5, n_iter=20)\n\nprint(\"Best parameters found:\", optimizer.max)\n</code></pre>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#why-bayesian-optimization-is-powerful","title":"Why Bayesian Optimization is Powerful?","text":"<p>\u2705 More efficient than grid/random search \u2192 Finds good hyperparameters in fewer evaluations.</p> <p>\u2705 Works well for expensive models (e.g., deep learning, reinforcement learning).</p> <p>\u2705 Uses prior knowledge to guide search intelligently.</p> <p>\u274c Downside?</p> <ul> <li> <p>Computationally expensive for very high-dimensional problems.</p> </li> <li> <p>Assumes a smooth objective function, which may not always hold.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#comparison-of-methods","title":"Comparison of Methods","text":"Method Strengths Weaknesses Grid Search Systematic, finds best result within search space Expensive, infeasible in high dimensions Random Search More efficient than grid search, better exploration No guarantee of best hyperparameters Bayesian Optimization Uses prior knowledge, efficient in low-data settings Computationally expensive in high dimensions","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#6-ensemble-methods","title":"(6) Ensemble Methods","text":"<ul> <li> <p>Bagging (Bootstrap Aggregating): Train multiple models on bootstrapped datasets (e.g., Random Forest).</p> </li> <li> <p>Boosting: Sequential training that corrects previous errors (e.g., AdaBoost, Gradient Boosting, XGBoost, LightGBM).</p> </li> <li> <p>Stacking: Combine multiple models via a meta-model.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#random-forest","title":"Random Forest","text":"Python<pre><code>from sklearn.ensemble import RandomForestRegressor\n\nrf = RandomForestRegressor(n_estimators=100, random_state=42)\n</code></pre> <p>Mean Squared Error (Loss): 0.008086484856903553</p> <p></p> <p>Random Forest is an ensemble learning method that builds multiple decision trees and combines their outputs to improve prediction accuracy and reduce overfitting.</p> <p>How Random Forest Works</p> <ul> <li> <p>Bootstrap Aggregation (Bagging):</p> </li> <li> <p>Random Forest trains multiple decision trees on different bootstrapped samples of the dataset.</p> </li> <li> <p>Each tree is trained on a random subset (without replacement) of the features.</p> </li> <li> <p>The predictions from all trees are averaged (for regression) or use majority voting (for classification).</p> </li> </ul> <p>Why it Works:</p> <ul> <li> <p>Reduces overfitting (compared to a single decision tree).</p> </li> <li> <p>Handles high-dimensional data well.</p> </li> <li> <p>Robust to noise and missing values.</p> </li> </ul> <p>Pros &amp; Cons</p> <p>\u2705 Reduces variance (compared to individual trees).</p> <p>\u2705 Handles categorical &amp; numerical features well.</p> <p>\u2705 Works well for large datasets.</p> <p>\u274c Slower than a single decision tree.</p> <p>\u274c Large ensembles can be computationally expensive.</p>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#gbdt-gradient-boosted-decision-trees","title":"GBDT (Gradient Boosted Decision Trees)","text":"Python<pre><code>import lightgbm as lgb\n\nlgb_train = lgb.Dataset(Z, label=Y[idx].tolist())\nparams = {'objective': 'regression', 'metric': 'mse', 'boosting_type': 'gbdt', 'verbose': -1}\nlgb_model = lgb.train(params, lgb_train, num_boost_round=100)\npredictions = lgb_model.predict(Z)\n</code></pre> <p>Mean Squared Error (Loss): 0.19826513528823853</p> <p></p> <p>GBDT (Gradient Boosted Decision Trees) is a powerful ensemble learning method that builds multiple decision trees sequentially to minimize a given loss function using gradient descent. It is widely used in machine learning for regression, classification, and ranking problems.</p> <p>How GBDT Works</p> <p>GBDT is based on the boosting technique, where models are trained sequentially, and each tree tries to correct the errors made by the previous ones.</p>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#step-by-step-process","title":"Step-by-Step Process:","text":"<ol> <li> <p>Start with a weak model</p> <ul> <li> <p>Usually, this is a simple decision tree (often a shallow one, also called a weak learner).</p> </li> <li> <p>The first tree predicts the target values roughly.</p> </li> </ul> </li> <li> <p>Compute the residual errors (gradients of the loss function)</p> <ul> <li>For regression:</li> </ul>  r_i = y_i - \\hat{y}_i  <ul> <li>For classification:</li> </ul>  r_i = -\\frac{\\partial L(y, \\hat{y})}{\\partial \\hat{y}}  <ul> <li>The model learns the difference (residuals) between the predicted and actual values.</li> </ul> </li> <li> <p>Train a new decision tree to predict the residuals</p> <ul> <li>This new tree focuses on correcting the errors made by the previous one.</li> </ul> </li> <li> <p>Update the prediction</p> <ul> <li>Add the new tree's predictions to the overall model:</li> </ul>  F_{m+1}(x) = F_m(x) + \\eta h_m(x)  <ul> <li>\\eta is the learning rate, which controls how much each tree contributes to the final prediction.</li> </ul> </li> <li> <p>Repeat the process</p> <ul> <li>Keep adding new trees until a stopping criterion is met (e.g., a fixed number of trees or no significant improvement in performance).</li> </ul> </li> </ol>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#why-gbdt-works-well","title":"Why GBDT Works Well","text":"<ul> <li> <p>Handles Non-Linearity: Unlike linear models, GBDT captures complex, non-linear relationships.</p> </li> <li> <p>Adaptive Learning: Each new tree corrects errors made by previous ones.</p> </li> <li> <p>Robust to Outliers: GBDT can be robust if loss functions like Huber loss are used.</p> </li> <li> <p>Feature Importance: It naturally provides feature importance rankings.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#xgboost-extreme-gradient-boosting","title":"XGBoost (Extreme Gradient Boosting)","text":"<p>XGBoost is an optimized implementation of gradient boosting that is highly efficient and widely used in machine learning competitions.</p> <p>How XGBoost Works</p> <ul> <li> <p>Gradient Boosting:</p> <ul> <li> <p>Unlike Random Forest (which trains trees independently), XGBoost trains trees sequentially, where each new tree corrects the errors of the previous ones.</p> </li> <li> <p>It minimizes a loss function using gradient descent, hence the name \"gradient boosting.\"</p> </li> </ul> </li> <li> <p>Key Optimizations:</p> <ul> <li> <p>Regularization: Adds L1/L2 penalties (like Lasso/Ridge) to prevent overfitting.</p> </li> <li> <p>Tree Pruning: Uses a maximum depth instead of splitting until pure.</p> </li> <li> <p>Handling Missing Values: Automatically learns best imputation.</p> </li> <li> <p>Parallelization: Efficiently builds trees using multi-threading.</p> </li> </ul> </li> </ul> <p>Pros &amp; Cons</p> <p>\u2705 Faster than traditional gradient boosting (due to optimizations).</p> <p>\u2705 Handles large-scale data efficiently.</p> <p>\u2705 Highly customizable with tunable hyperparameters.</p> <p>\u274c Can be prone to overfitting if not tuned properly.</p> <p>\u274c Sensitive to hyperparameter settings.</p>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#lightgbm-light-gradient-boosting-machine","title":"LightGBM (Light Gradient Boosting Machine)","text":"<p>LightGBM is another gradient boosting library, optimized for speed and efficiency.</p> <p>How LightGBM Works</p> <ul> <li> <p>Key Differences from XGBoost:</p> </li> <li> <p>Leaf-wise tree growth:</p> <ul> <li> <p>XGBoost grows trees level-wise (uniform expansion).</p> </li> <li> <p>LightGBM grows trees leaf-wise (expands the most promising leaf first), leading to deeper trees and faster convergence.</p> </li> </ul> </li> <li> <p>Histogram-based splitting:</p> <ul> <li>Instead of checking every data point for splits, LightGBM groups values into histogram bins, reducing computation.</li> </ul> </li> <li> <p>Better memory efficiency:</p> <ul> <li>Uses less RAM than XGBoost due to histogram-based processing.</li> </ul> </li> </ul> <p>Pros &amp; Cons</p> <p>\u2705 Much faster than XGBoost, especially for large datasets.</p> <p>\u2705 Handles categorical features without needing one-hot encoding.</p> <p>\u2705 Scales well to large datasets.</p> <p>\u274c May be less interpretable than XGBoost.</p> <p>\u274c Can overfit if not properly tuned.</p> <p>When to Use Which?</p> <ul> <li> <p>Random Forest \u2192 When you need an interpretable model and have limited data.</p> </li> <li> <p>XGBoost \u2192 When you need high accuracy and have time for hyperparameter tuning.</p> </li> <li> <p>LightGBM \u2192 When you have large datasets and need fast training.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#i-model-uncertainty-bayesianprobabilistic-models","title":"I. Model Uncertainty (Bayesian/Probabilistic Models)","text":"<ul> <li> <p>Bayesian Neural Networks: Treats weights as probability distributions.</p> </li> <li> <p>Gaussian Processes: Models uncertainty in regression.</p> </li> <li> <p>Monte Carlo Dropout: Uses dropout at inference to approximate Bayesian uncertainty.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#bayesian-regression","title":"Bayesian Regression","text":"Python<pre><code>reg = linear_model.BayesianRidge()\n</code></pre> <p>Mean Squared Error (Loss): 0.03729788959026337</p> <p></p> <p>Bayesian Regression is a probabilistic approach to linear regression. Instead of estimating a single set of parameters (as in ordinary least squares), it treats the parameters of the regression model as random variables with a prior distribution.</p> <ol> <li> <p>Model Assumptions:</p> <ul> <li> <p>Assume a linear model for the data:</p>  y = X\\beta + \\epsilon  <p>where:</p> </li> <li> <p>y is the vector of observed values,</p> </li> <li> <p>X is the design matrix (input features),</p> </li> <li> <p>\\beta is the vector of regression coefficients (parameters),</p> </li> <li> <p>\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I) is the Gaussian noise with variance \\sigma^2.</p> </li> </ul> </li> <li> <p>Prior:</p> <ul> <li>Assume a Gaussian prior on the coefficients \\beta:</li> </ul>  p(\\beta) = \\mathcal{N}(\\beta \\mid 0, \\tau^2 I)  <p>where \\tau^2 is the prior variance of the coefficients.</p> </li> <li> <p>Likelihood:</p> <ul> <li>The likelihood function given the data is:</li> </ul>  p(y \\mid X, \\beta, \\sigma^2) = \\mathcal{N}(y \\mid X\\beta, \\sigma^2 I)  <p>This is a Gaussian distribution with mean X\\beta and covariance \\sigma^2 I.</p> </li> <li> <p>Posterior (Bayes' Theorem):</p> <ul> <li>Using Bayes' Theorem, the posterior distribution of \\beta given the data is:</li> </ul>  p(\\beta \\mid X, y, \\sigma^2) \\propto p(y \\mid X, \\beta, \\sigma^2) p(\\beta)  </li> <li> <p>Maximum Likelihood Estimation:</p> <ul> <li> <p>To find the maximum likelihood estimates (MLE) of the parameters \\beta and \\sigma^2, we can maximize the likelihood function:</p>  \\mathcal{L}(\\beta, \\sigma^2 \\mid X, y) = p(y \\mid X, \\beta, \\sigma^2)  </li> <li> <p>The log-likelihood is:</p>  \\log \\mathcal{L}(\\beta, \\sigma^2 \\mid X, y) = -\\frac{N}{2} \\log (2\\pi \\sigma^2) - \\frac{1}{2\\sigma^2} \\| y - X\\beta \\|^2  </li> <li> <p>To maximize this, take the derivative with respect to \\beta and \\sigma^2, set them to zero, and solve for \\beta and \\sigma^2.</p> </li> </ul> </li> </ol>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#mle-for-betabeta","title":"MLE for \\beta","text":"<ul> <li>The MLE of \\beta (ignoring \\sigma^2) is the ordinary least squares (OLS) solution:</li> </ul>  \\hat{\\beta} = (X^T X)^{-1} X^T y","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#mle-for-sigma2sigma2","title":"MLE for \\sigma^2","text":"<ul> <li>After finding \\hat{\\beta}, the MLE of \\sigma^2 is:</li> </ul>  \\hat{\\sigma}^2 = \\frac{1}{N} \\| y - X\\hat{\\beta} \\|^2","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#computational-techniques","title":"Computational Techniques:","text":"<ul> <li> <p>Analytical Approach: In most cases (like when the prior and likelihood are Gaussian), the posterior distribution is also Gaussian, so you can compute it analytically. This is the standard approach for simple Bayesian linear regression.</p> </li> <li> <p>Markov Chain Monte Carlo (MCMC): For more complex models (e.g., non-linear regression or non-Gaussian priors), you can use MCMC methods (such as Metropolis-Hastings or Gibbs sampling) to sample from the posterior distribution of the parameters.</p> </li> <li> <p>Iterative Methods (Variational Inference): For more computationally complex models, you might use iterative methods like Variational Inference or Expectation-Maximization (EM) to approximate the posterior.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#gaussian-processes","title":"Gaussian Processes","text":"<p>A Gaussian Process (GP) is a non-parametric model used for regression tasks. Unlike typical regression models that assume a functional form (like linear regression), GPR assumes that the data is drawn from a Gaussian distribution over functions.</p> <p>[! Definition] Definition A Gaussian process is a collection of random variables, any finite number of which have a joint Gaussian distribution. It is completely specified by a mean function m(x) and a covariance function (or kernel) k(x, x'), which defines the correlation between inputs.</p>  f(x) \\sim \\mathcal{GP}(m(x), k(x, x'))  <p>Where:</p> <ul> <li> <p>f(x) is the function value at input x,</p> </li> <li> <p>m(x) is the mean function (often assumed to be zero),</p> </li> <li> <p>k(x, x') is the covariance function, which defines the relationship between points x and x'.</p> </li> <li> <p>Model Assumptions:</p> <ul> <li> <p>Assume the output y is a realization of a Gaussian process:</p>    f(x) \\sim \\mathcal{GP}(0, k(x, x'))   </li> </ul> <p>where k(x, x') is a covariance kernel that defines the relationship between the points x and x'.</p> </li> <li> <p>Likelihood:</p> <ul> <li> <p>Given N training points X = \\{x_1, x_2, \u2026, x_N\\} and corresponding outputs y = \\{y_1, y_2, \u2026, y_N\\}, the likelihood of the observations is given by the multivariate normal distribution:</p>    p(y \\mid X, \\theta) = \\mathcal{N}(y \\mid 0, K(X, X) + \\sigma^2 I)  <p>where:</p> </li> <li> <p>K(X, X) is the covariance matrix computed using the kernel function k(x, x'),</p> </li> <li> <p>\\sigma^2 is the noise variance, and</p> </li> <li> <p>I is the identity matrix.</p> </li> </ul> </li> <li> <p>Maximizing the Likelihood:</p> <ul> <li> <p>The log-likelihood is:</p>    \\log p(y \\mid X, \\theta) = -\\frac{1}{2} y^T (K(X, X) + \\sigma^2 I)^{-1} y - \\frac{1}{2} \\log \\det (K(X, X) + \\sigma^2 I) - \\frac{N}{2} \\log 2\\pi      </li> <li> <p>Here, \\theta refers to the kernel hyperparameters (e.g., length scale, variance) and \\sigma^2 is the noise parameter.</p> </li> </ul> </li> <li> <p>Optimization:</p> <ul> <li> <p>To find the maximum likelihood estimate (MLE) of the kernel parameters \\theta and \\sigma^2, we maximize the log-likelihood:</p>    \\hat{\\theta}, \\hat{\\sigma^2} = \\arg \\max_\\theta \\log p(y \\mid X, \\theta)      </li> <li> <p>This is typically done via numerical optimization techniques like gradient descent or conjugate gradient methods, since the log-likelihood is non-linear with respect to the kernel parameters.</p> </li> </ul> </li> <li> <p>Prediction:</p> <ul> <li> <p>Once the kernel parameters are optimized, predictions at a new test point x_* can be made by conditioning the Gaussian process on the training data. The predictive mean and variance are given by:</p>  \\mu_* = k(x_*, X) [K(X, X) + \\sigma^2 I]^{-1} y   \\sigma_*^2 = k(x_*, x_*) - k(x_*, X) [K(X, X) + \\sigma^2 I]^{-1} k(X, x_*)  </li> <li> <p>Here, k(x_*, X) is the covariance between the test point x_* and the training points X, and k(x_*, x_*) is the covariance at the test point.</p> </li> </ul> </li> <li> <p>Model Definition:</p> <p>A Gaussian Process defines a prior over functions. We assume the function values f(x) at any set of points X follow a multivariate normal distribution:</p>    f(X) \\sim \\mathcal{N}(0, K(X, X))  <p>where K(X, X) is the covariance matrix determined by the chosen kernel (covariance function). Common kernels include the RBF kernel (Radial Basis Function), Matern kernel, etc.</p> </li> <li> <p>Likelihood Function:</p> <p>Given the observations y = f(X) + \\epsilon, where \\epsilon is noise, the likelihood function is:</p>    p(y \\mid X, \\theta) = \\mathcal{N}(y \\mid 0, K(X, X) + \\sigma^2 I)  <p>where \\sigma^2 is the noise variance.</p> </li> <li> <p>Posterior Distribution:</p> <p>The posterior distribution of the function values f_* at new test points X_*, given the training data (X, y), is also Gaussian:</p>    p(f_* \\mid X_*, X, y) = \\mathcal{N}(f_* \\mid \\mu_*, \\Sigma_*)     <p>where:</p> <ul> <li> <p>\\mu_* is the mean of the posterior, and</p> </li> <li> <p>\\Sigma_* is the covariance (uncertainty).</p> </li> </ul> <p>The mean and covariance of the posterior are given by:</p>    \\mu_* = K(X_*, X)[K(X, X) + \\sigma^2 I]^{-1} y       \\Sigma_* = K(X_*, X_*) - K(X_*, X)[K(X, X) + \\sigma^2 I]^{-1} K(X, X_*)   </li> <li> <p>Iterative Methods:</p> <ul> <li>In practice, iterative optimization (e.g., gradient descent or conjugate gradient methods) is used to find the optimal kernel hyperparameters by maximizing the log marginal likelihood.</li> </ul> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#j-optimization-algorithms-improving-model-training","title":"J. Optimization Algorithms (Improving Model Training)","text":"<ul> <li> <p>Gradient Descent Variants:</p> <ul> <li> <p>SGD (Stochastic Gradient Descent)</p> </li> <li> <p>Momentum-based GD</p> </li> <li> <p>Adam, RMSprop, Adagrad</p> </li> </ul> </li> <li> <p>Second-order Optimization: Newton's method, Quasi-Newton methods (L-BFGS).</p> </li> <li> <p>Adaptive Learning Rate: Learning rate schedules (cosine annealing, warm restarts).</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#newtons-method","title":"Newton's Method","text":"<p>Newton's method uses the Hessian matrix (second derivative) for optimization:</p>  \\theta_{t+1} = \\theta_t - H^{-1} \\nabla f(\\theta)  <p>where:</p> <ul> <li> <p>H is the Hessian matrix (second derivative of the loss function).</p> </li> <li> <p>\\nabla f(\\theta) is the gradient.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#momentum-based-update","title":"Momentum-based Update","text":"<p>Momentum accelerates gradient descent by adding a fraction of the previous update to the current one:</p>  v_t = \\beta v_{t-1} - \\alpha \\nabla f(\\theta_t)   \\theta_{t+1} = \\theta_t + v_t  <p>where:</p> <ul> <li> <p>v_t is the velocity term,</p> </li> <li> <p>\\beta is the momentum coefficient (e.g., 0.9),</p> </li> <li> <p>\\alpha is the learning rate. Python<pre><code>iterations = 500\nstep_size = 0.1\nbeta = 0.9  # Momentum coefficient\ndataset = (X, Y)\n\nfor order in range(2, 15, 2):\n    weights = np.ones(order) * 1.5\n    velocity = np.zeros(order)  # Initialize velocity\n\n    for i in range(iterations):\n        params = weights\n        loss_ = loss(params, dataset)\n        params_grad = loss_grad(params, dataset)\n\n        # Update parameters using Momentum\n        for j in range(order):\n            velocity[j] = beta * velocity[j] - step_size * params_grad[j]  # Apply momentum update\n            weights = weights.at[j].set(weights[j] + velocity[j])  # Update weights\n</code></pre></p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#k-model-architecture-optimization-deep-learning","title":"K. Model Architecture Optimization (Deep Learning)","text":"<ul> <li> <p>Residual Networks (ResNet): Helps with vanishing gradients.</p> </li> <li> <p>Transformers: Attention-based models (BERT, GPT).</p> </li> <li> <p>Neural Architecture Search (NAS): Auto-tuning model structure.</p> </li> </ul>","tags":["Note"]},{"location":"Intro-Machine-Learning/01.%20Introduction/#l-interpretability-explainability","title":"L. Interpretability &amp; Explainability","text":"<ul> <li> <p>SHAP, LIME: Explainable AI tools.</p> </li> <li> <p>Feature Importance Methods: Permutation importance, gradient-based saliency maps.</p> </li> </ul>","tags":["Note"]}]}